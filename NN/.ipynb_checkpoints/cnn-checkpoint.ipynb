{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('C:/Users/ASUS/Desktop/p/CB ML/convolution-neural-network-tutorial/Dataset/fashion-mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64), array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "X = X.values\n",
    "x = X[:,1:]\n",
    "y = X[:,0]\n",
    "print(x.shape,y.shape)\n",
    "print(np.unique(y,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce9ec75ba8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[1000].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.01568627]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.00392157]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.01176471]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.00784314]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.00392157]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.00392157]\n",
      "   [0.01176471]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.00784314]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.45490196]\n",
      "   ...\n",
      "   [0.78431373]\n",
      "   [0.11372549]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.01568627]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.01568627]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.00784314]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]\n",
      "\n",
      "  [[0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   ...\n",
      "   [0.        ]\n",
      "   [0.        ]\n",
      "   [0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape((-1,28,28,1))/255\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y,num_classes=10)\n",
    "print(x.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0721 15:22:02.835831  5140 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0721 15:22:03.252918  5140 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0721 15:22:03.343462  5140 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0721 15:22:03.432610  5140 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0721 15:22:03.568775  5140 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0721 15:22:03.593638  5140 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Cnn model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu')) # 5x5\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(Conv2D(20,(3,3),activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 20)          23060     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 128,542\n",
      "Trainable params: 128,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0721 15:29:20.376987  5140 deprecation.py:323] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0721 15:29:20.453777  5140 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 1.3155 - acc: 0.5545 - val_loss: 0.8127 - val_acc: 0.6780\n",
      "Epoch 2/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.7385 - acc: 0.7201 - val_loss: 0.6239 - val_acc: 0.7680\n",
      "Epoch 3/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5839 - acc: 0.7818 - val_loss: 0.5378 - val_acc: 0.8060\n",
      "Epoch 4/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5201 - acc: 0.8047 - val_loss: 0.4842 - val_acc: 0.8185\n",
      "Epoch 5/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4733 - acc: 0.8264 - val_loss: 0.4679 - val_acc: 0.8290\n",
      "Epoch 6/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4530 - acc: 0.8346 - val_loss: 0.4226 - val_acc: 0.8525\n",
      "Epoch 7/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.4102 - acc: 0.8479 - val_loss: 0.4277 - val_acc: 0.8510\n",
      "Epoch 8/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3973 - acc: 0.8555 - val_loss: 0.4013 - val_acc: 0.8600\n",
      "Epoch 9/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3772 - acc: 0.8616 - val_loss: 0.3806 - val_acc: 0.8635\n",
      "Epoch 10/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3532 - acc: 0.8704 - val_loss: 0.3895 - val_acc: 0.8675\n",
      "Epoch 11/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3418 - acc: 0.8764 - val_loss: 0.3789 - val_acc: 0.8720\n",
      "Epoch 12/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3150 - acc: 0.8819 - val_loss: 0.3819 - val_acc: 0.8630\n",
      "Epoch 13/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3010 - acc: 0.8877 - val_loss: 0.3565 - val_acc: 0.8805\n",
      "Epoch 14/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2955 - acc: 0.8932 - val_loss: 0.3598 - val_acc: 0.8795\n",
      "Epoch 15/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2843 - acc: 0.8967 - val_loss: 0.3496 - val_acc: 0.8880\n",
      "Epoch 16/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2738 - acc: 0.8986 - val_loss: 0.3787 - val_acc: 0.8650\n",
      "Epoch 17/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.2578 - acc: 0.9051 - val_loss: 0.3623 - val_acc: 0.8730\n",
      "Epoch 18/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2499 - acc: 0.9093 - val_loss: 0.3646 - val_acc: 0.8680\n",
      "Epoch 19/20\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.2367 - acc: 0.9100 - val_loss: 0.3801 - val_acc: 0.8640\n",
      "Epoch 20/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.2267 - acc: 0.9159 - val_loss: 0.3558 - val_acc: 0.8775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce9eb82470>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=20,shuffle=True,batch_size=256,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
