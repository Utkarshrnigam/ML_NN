{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./Dataset/classy_points/Logistic_X_Train.csv\")\n",
    "Y_train = pd.read_csv(\"./Dataset/classy_points/Logistic_Y_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 2) (2250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(10,activation='relu',input_shape=(2,)))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_val = X_train[:250]\n",
    "y_val = Y_train[:250]\n",
    "\n",
    "X_newTrain = X_train[250:]\n",
    "Y_newTrain = Y_train[250:]\n",
    "print(Y_newTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 250 samples\n",
      "Epoch 1/70\n",
      "2250/2250 [==============================] - 1s 635us/step - loss: 0.6403 - val_loss: 0.6089\n",
      "Epoch 2/70\n",
      "2250/2250 [==============================] - 0s 32us/step - loss: 0.5877 - val_loss: 0.5609\n",
      "Epoch 3/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.5459 - val_loss: 0.5275\n",
      "Epoch 4/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.5158 - val_loss: 0.5026\n",
      "Epoch 5/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.4908 - val_loss: 0.4783\n",
      "Epoch 6/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.4644 - val_loss: 0.4519\n",
      "Epoch 7/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.4367 - val_loss: 0.4254\n",
      "Epoch 8/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.4086 - val_loss: 0.3990\n",
      "Epoch 9/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.3819 - val_loss: 0.3750\n",
      "Epoch 10/70\n",
      "2250/2250 [==============================] - 0s 39us/step - loss: 0.3582 - val_loss: 0.3543\n",
      "Epoch 11/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.3388 - val_loss: 0.3382\n",
      "Epoch 12/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.3243 - val_loss: 0.3259\n",
      "Epoch 13/70\n",
      "2250/2250 [==============================] - 0s 31us/step - loss: 0.3129 - val_loss: 0.3166\n",
      "Epoch 14/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.3040 - val_loss: 0.3084\n",
      "Epoch 15/70\n",
      "2250/2250 [==============================] - 0s 33us/step - loss: 0.2969 - val_loss: 0.3004\n",
      "Epoch 16/70\n",
      "2250/2250 [==============================] - 0s 31us/step - loss: 0.2906 - val_loss: 0.2922\n",
      "Epoch 17/70\n",
      "2250/2250 [==============================] - 0s 27us/step - loss: 0.2843 - val_loss: 0.2831\n",
      "Epoch 18/70\n",
      "2250/2250 [==============================] - 0s 26us/step - loss: 0.2763 - val_loss: 0.2711\n",
      "Epoch 19/70\n",
      "2250/2250 [==============================] - 0s 27us/step - loss: 0.2669 - val_loss: 0.2584\n",
      "Epoch 20/70\n",
      "2250/2250 [==============================] - 0s 27us/step - loss: 0.2584 - val_loss: 0.2490\n",
      "Epoch 21/70\n",
      "2250/2250 [==============================] - 0s 27us/step - loss: 0.2521 - val_loss: 0.2412\n",
      "Epoch 22/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.2463 - val_loss: 0.2343\n",
      "Epoch 23/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.2410 - val_loss: 0.2282\n",
      "Epoch 24/70\n",
      "2250/2250 [==============================] - 0s 31us/step - loss: 0.2356 - val_loss: 0.2226\n",
      "Epoch 25/70\n",
      "2250/2250 [==============================] - 0s 40us/step - loss: 0.2311 - val_loss: 0.2166\n",
      "Epoch 26/70\n",
      "2250/2250 [==============================] - 0s 28us/step - loss: 0.2247 - val_loss: 0.2106\n",
      "Epoch 27/70\n",
      "2250/2250 [==============================] - 0s 33us/step - loss: 0.2197 - val_loss: 0.2051\n",
      "Epoch 28/70\n",
      "2250/2250 [==============================] - 0s 31us/step - loss: 0.2150 - val_loss: 0.2002\n",
      "Epoch 29/70\n",
      "2250/2250 [==============================] - 0s 31us/step - loss: 0.2101 - val_loss: 0.1956\n",
      "Epoch 30/70\n",
      "2250/2250 [==============================] - 0s 35us/step - loss: 0.2054 - val_loss: 0.1906\n",
      "Epoch 31/70\n",
      "2250/2250 [==============================] - 0s 39us/step - loss: 0.2007 - val_loss: 0.1856\n",
      "Epoch 32/70\n",
      "2250/2250 [==============================] - 0s 36us/step - loss: 0.1958 - val_loss: 0.1820\n",
      "Epoch 33/70\n",
      "2250/2250 [==============================] - 0s 35us/step - loss: 0.1913 - val_loss: 0.1768\n",
      "Epoch 34/70\n",
      "2250/2250 [==============================] - 0s 34us/step - loss: 0.1870 - val_loss: 0.1731\n",
      "Epoch 35/70\n",
      "2250/2250 [==============================] - 0s 31us/step - loss: 0.1826 - val_loss: 0.1698\n",
      "Epoch 36/70\n",
      "2250/2250 [==============================] - 0s 32us/step - loss: 0.1783 - val_loss: 0.1660\n",
      "Epoch 37/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.1742 - val_loss: 0.1623\n",
      "Epoch 38/70\n",
      "2250/2250 [==============================] - 0s 38us/step - loss: 0.1703 - val_loss: 0.1584\n",
      "Epoch 39/70\n",
      "2250/2250 [==============================] - 0s 43us/step - loss: 0.1669 - val_loss: 0.1546\n",
      "Epoch 40/70\n",
      "2250/2250 [==============================] - 0s 37us/step - loss: 0.1622 - val_loss: 0.1532\n",
      "Epoch 41/70\n",
      "2250/2250 [==============================] - 0s 33us/step - loss: 0.1592 - val_loss: 0.1491\n",
      "Epoch 42/70\n",
      "2250/2250 [==============================] - 0s 38us/step - loss: 0.1551 - val_loss: 0.1468\n",
      "Epoch 43/70\n",
      "2250/2250 [==============================] - 0s 33us/step - loss: 0.1520 - val_loss: 0.1437\n",
      "Epoch 44/70\n",
      "2250/2250 [==============================] - 0s 33us/step - loss: 0.1487 - val_loss: 0.1406\n",
      "Epoch 45/70\n",
      "2250/2250 [==============================] - 0s 37us/step - loss: 0.1453 - val_loss: 0.1383\n",
      "Epoch 46/70\n",
      "2250/2250 [==============================] - 0s 36us/step - loss: 0.1423 - val_loss: 0.1360\n",
      "Epoch 47/70\n",
      "2250/2250 [==============================] - 0s 35us/step - loss: 0.1394 - val_loss: 0.1333\n",
      "Epoch 48/70\n",
      "2250/2250 [==============================] - 0s 43us/step - loss: 0.1365 - val_loss: 0.1314\n",
      "Epoch 49/70\n",
      "2250/2250 [==============================] - 0s 43us/step - loss: 0.1337 - val_loss: 0.1289\n",
      "Epoch 50/70\n",
      "2250/2250 [==============================] - 0s 25us/step - loss: 0.1313 - val_loss: 0.1271\n",
      "Epoch 51/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.1293 - val_loss: 0.1253\n",
      "Epoch 52/70\n",
      "2250/2250 [==============================] - 0s 22us/step - loss: 0.1269 - val_loss: 0.1237\n",
      "Epoch 53/70\n",
      "2250/2250 [==============================] - 0s 22us/step - loss: 0.1248 - val_loss: 0.1222\n",
      "Epoch 54/70\n",
      "2250/2250 [==============================] - 0s 22us/step - loss: 0.1231 - val_loss: 0.1207\n",
      "Epoch 55/70\n",
      "2250/2250 [==============================] - 0s 23us/step - loss: 0.1212 - val_loss: 0.1193\n",
      "Epoch 56/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.1195 - val_loss: 0.1179\n",
      "Epoch 57/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.1179 - val_loss: 0.1172\n",
      "Epoch 58/70\n",
      "2250/2250 [==============================] - 0s 30us/step - loss: 0.1165 - val_loss: 0.1163\n",
      "Epoch 59/70\n",
      "2250/2250 [==============================] - 0s 28us/step - loss: 0.1153 - val_loss: 0.1158\n",
      "Epoch 60/70\n",
      "2250/2250 [==============================] - 0s 22us/step - loss: 0.1139 - val_loss: 0.1143\n",
      "Epoch 61/70\n",
      "2250/2250 [==============================] - 0s 21us/step - loss: 0.1125 - val_loss: 0.1132\n",
      "Epoch 62/70\n",
      "2250/2250 [==============================] - 0s 21us/step - loss: 0.1115 - val_loss: 0.1124\n",
      "Epoch 63/70\n",
      "2250/2250 [==============================] - 0s 21us/step - loss: 0.1104 - val_loss: 0.1116\n",
      "Epoch 64/70\n",
      "2250/2250 [==============================] - 0s 20us/step - loss: 0.1097 - val_loss: 0.1117\n",
      "Epoch 65/70\n",
      "2250/2250 [==============================] - 0s 22us/step - loss: 0.1092 - val_loss: 0.1101\n",
      "Epoch 66/70\n",
      "2250/2250 [==============================] - 0s 23us/step - loss: 0.1080 - val_loss: 0.1094\n",
      "Epoch 67/70\n",
      "2250/2250 [==============================] - 0s 26us/step - loss: 0.1067 - val_loss: 0.1097\n",
      "Epoch 68/70\n",
      "2250/2250 [==============================] - 0s 23us/step - loss: 0.1060 - val_loss: 0.1084\n",
      "Epoch 69/70\n",
      "2250/2250 [==============================] - 0s 21us/step - loss: 0.1058 - val_loss: 0.1079\n",
      "Epoch 70/70\n",
      "2250/2250 [==============================] - 0s 29us/step - loss: 0.1047 - val_loss: 0.1082\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,Y_train,epochs=70,batch_size=64,validation_data =(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-249-88157d59df24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(h['val_acc'],label=\"val_acc\")\n",
    "plt.plot(h['acc'],label=\"acc\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train,Y_train)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"./Dataset/classy_points/Logistic_X_Test.csv\")\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newOutput = []\n",
    "m = output.shape[0]\n",
    "for i in range(m):\n",
    "    if output[i]>=0.5:\n",
    "        newOutput.append(\"1\")\n",
    "    else:\n",
    "        newOutput.append(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(newOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  pd.DataFrame(data=newOutput,columns=[\"label\"]) \n",
    "y.to_csv(\"clssfy_points.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
