{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/pokemon/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304, 2)\n"
     ]
    }
   ],
   "source": [
    "X = df.values\n",
    "print(X.shape)\n",
    "X_values = []\n",
    "Y_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon={\n",
    "    'Pikachu':0,\n",
    "    'Bulbasaur':1,\n",
    "    'Charmander':2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "for i in range(m):\n",
    "    title = X[i][0]\n",
    "    img = cv2.imread(\"Dataset/pokemon/Images/\"+title)\n",
    "    try:\n",
    "        if img == None:\n",
    "            continue\n",
    "    except:\n",
    "        \n",
    "        \n",
    "        X_values.append(img)\n",
    "        Y_values.append(pokemon[X[i][1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 30000)\n",
      "(136,)\n"
     ]
    }
   ],
   "source": [
    "X_values = np.array(X_values)\n",
    "Y_values = np.array(Y_values)\n",
    "print(X_values.shape)\n",
    "print(Y_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0727 01:15:47.738617  9680 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0727 01:15:47.742604  9680 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0727 01:15:47.998687  9680 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0727 01:15:48.056534  9680 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0727 01:15:48.085490  9680 deprecation_wrapper.py:119] From c:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu')) # 5x5\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(Conv2D(20,(3,3),activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (136, 30000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6eec0ccbd18b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (136, 30000)"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_values,Y_values,epochs=20,shuffle=True,batch_size=256,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 0 loss 3.3305\n",
      "Epochs 1 loss 3.0560\n",
      "Epochs 2 loss 2.8973\n",
      "Epochs 3 loss 2.7534\n",
      "Epochs 4 loss 2.6220\n",
      "Epochs 5 loss 2.5016\n",
      "Epochs 6 loss 2.3916\n",
      "Epochs 7 loss 2.2912\n",
      "Epochs 8 loss 2.1984\n",
      "Epochs 9 loss 2.1109\n",
      "Epochs 10 loss 2.0270\n",
      "Epochs 11 loss 1.9457\n",
      "Epochs 12 loss 1.8668\n",
      "Epochs 13 loss 1.7904\n",
      "Epochs 14 loss 1.7169\n",
      "Epochs 15 loss 1.6463\n",
      "Epochs 16 loss 1.5784\n",
      "Epochs 17 loss 1.5132\n",
      "Epochs 18 loss 1.4504\n",
      "Epochs 19 loss 1.3902\n",
      "Epochs 20 loss 1.3328\n",
      "Epochs 21 loss 1.2788\n",
      "Epochs 22 loss 1.2283\n",
      "Epochs 23 loss 1.1814\n",
      "Epochs 24 loss 1.1378\n",
      "Epochs 25 loss 1.0972\n",
      "Epochs 26 loss 1.0595\n",
      "Epochs 27 loss 1.0243\n",
      "Epochs 28 loss 0.9915\n",
      "Epochs 29 loss 0.9607\n",
      "Epochs 30 loss 0.9319\n",
      "Epochs 31 loss 0.9048\n",
      "Epochs 32 loss 0.8794\n",
      "Epochs 33 loss 0.8555\n",
      "Epochs 34 loss 0.8330\n",
      "Epochs 35 loss 0.8118\n",
      "Epochs 36 loss 0.7918\n",
      "Epochs 37 loss 0.7728\n",
      "Epochs 38 loss 0.7547\n",
      "Epochs 39 loss 0.7375\n",
      "Epochs 40 loss 0.7210\n",
      "Epochs 41 loss 0.7052\n",
      "Epochs 42 loss 0.6900\n",
      "Epochs 43 loss 0.6752\n",
      "Epochs 44 loss 0.6607\n",
      "Epochs 45 loss 0.6466\n",
      "Epochs 46 loss 0.6327\n",
      "Epochs 47 loss 0.6190\n",
      "Epochs 48 loss 0.6055\n",
      "Epochs 49 loss 0.5923\n",
      "Epochs 50 loss 0.5794\n",
      "Epochs 51 loss 0.5668\n",
      "Epochs 52 loss 0.5546\n",
      "Epochs 53 loss 0.5427\n",
      "Epochs 54 loss 0.5312\n",
      "Epochs 55 loss 0.5200\n",
      "Epochs 56 loss 0.5091\n",
      "Epochs 57 loss 0.4985\n",
      "Epochs 58 loss 0.4881\n",
      "Epochs 59 loss 0.4780\n",
      "Epochs 60 loss 0.4681\n",
      "Epochs 61 loss 0.4585\n",
      "Epochs 62 loss 0.4491\n",
      "Epochs 63 loss 0.4400\n",
      "Epochs 64 loss 0.4311\n",
      "Epochs 65 loss 0.4225\n",
      "Epochs 66 loss 0.4142\n",
      "Epochs 67 loss 0.4061\n",
      "Epochs 68 loss 0.3983\n",
      "Epochs 69 loss 0.3907\n",
      "Epochs 70 loss 0.3834\n",
      "Epochs 71 loss 0.3765\n",
      "Epochs 72 loss 0.3697\n",
      "Epochs 73 loss 0.3633\n",
      "Epochs 74 loss 0.3571\n",
      "Epochs 75 loss 0.3511\n",
      "Epochs 76 loss 0.3453\n",
      "Epochs 77 loss 0.3398\n",
      "Epochs 78 loss 0.3345\n",
      "Epochs 79 loss 0.3294\n",
      "Epochs 80 loss 0.3244\n",
      "Epochs 81 loss 0.3196\n",
      "Epochs 82 loss 0.3150\n",
      "Epochs 83 loss 0.3105\n",
      "Epochs 84 loss 0.3061\n",
      "Epochs 85 loss 0.3019\n",
      "Epochs 86 loss 0.2977\n",
      "Epochs 87 loss 0.2937\n",
      "Epochs 88 loss 0.2898\n",
      "Epochs 89 loss 0.2860\n",
      "Epochs 90 loss 0.2823\n",
      "Epochs 91 loss 0.2787\n",
      "Epochs 92 loss 0.2751\n",
      "Epochs 93 loss 0.2717\n",
      "Epochs 94 loss 0.2683\n",
      "Epochs 95 loss 0.2650\n",
      "Epochs 96 loss 0.2618\n",
      "Epochs 97 loss 0.2586\n",
      "Epochs 98 loss 0.2555\n",
      "Epochs 99 loss 0.2525\n",
      "Epochs 100 loss 0.2496\n",
      "Epochs 101 loss 0.2467\n",
      "Epochs 102 loss 0.2439\n",
      "Epochs 103 loss 0.2411\n",
      "Epochs 104 loss 0.2384\n",
      "Epochs 105 loss 0.2358\n",
      "Epochs 106 loss 0.2331\n",
      "Epochs 107 loss 0.2306\n",
      "Epochs 108 loss 0.2281\n",
      "Epochs 109 loss 0.2256\n",
      "Epochs 110 loss 0.2232\n",
      "Epochs 111 loss 0.2208\n",
      "Epochs 112 loss 0.2184\n",
      "Epochs 113 loss 0.2161\n",
      "Epochs 114 loss 0.2138\n",
      "Epochs 115 loss 0.2115\n",
      "Epochs 116 loss 0.2093\n",
      "Epochs 117 loss 0.2071\n",
      "Epochs 118 loss 0.2049\n",
      "Epochs 119 loss 0.2028\n",
      "Epochs 120 loss 0.2007\n",
      "Epochs 121 loss 0.1987\n",
      "Epochs 122 loss 0.1967\n",
      "Epochs 123 loss 0.1948\n",
      "Epochs 124 loss 0.1929\n",
      "Epochs 125 loss 0.1911\n",
      "Epochs 126 loss 0.1893\n",
      "Epochs 127 loss 0.1876\n",
      "Epochs 128 loss 0.1859\n",
      "Epochs 129 loss 0.1842\n",
      "Epochs 130 loss 0.1826\n",
      "Epochs 131 loss 0.1811\n",
      "Epochs 132 loss 0.1795\n",
      "Epochs 133 loss 0.1781\n",
      "Epochs 134 loss 0.1766\n",
      "Epochs 135 loss 0.1752\n",
      "Epochs 136 loss 0.1738\n",
      "Epochs 137 loss 0.1724\n",
      "Epochs 138 loss 0.1711\n",
      "Epochs 139 loss 0.1697\n",
      "Epochs 140 loss 0.1684\n",
      "Epochs 141 loss 0.1672\n",
      "Epochs 142 loss 0.1659\n",
      "Epochs 143 loss 0.1647\n",
      "Epochs 144 loss 0.1635\n",
      "Epochs 145 loss 0.1623\n",
      "Epochs 146 loss 0.1611\n",
      "Epochs 147 loss 0.1600\n",
      "Epochs 148 loss 0.1588\n",
      "Epochs 149 loss 0.1577\n",
      "Epochs 150 loss 0.1566\n",
      "Epochs 151 loss 0.1555\n",
      "Epochs 152 loss 0.1544\n",
      "Epochs 153 loss 0.1533\n",
      "Epochs 154 loss 0.1522\n",
      "Epochs 155 loss 0.1512\n",
      "Epochs 156 loss 0.1502\n",
      "Epochs 157 loss 0.1491\n",
      "Epochs 158 loss 0.1481\n",
      "Epochs 159 loss 0.1471\n",
      "Epochs 160 loss 0.1461\n",
      "Epochs 161 loss 0.1451\n",
      "Epochs 162 loss 0.1441\n",
      "Epochs 163 loss 0.1432\n",
      "Epochs 164 loss 0.1422\n",
      "Epochs 165 loss 0.1412\n",
      "Epochs 166 loss 0.1403\n",
      "Epochs 167 loss 0.1394\n",
      "Epochs 168 loss 0.1384\n",
      "Epochs 169 loss 0.1375\n",
      "Epochs 170 loss 0.1366\n",
      "Epochs 171 loss 0.1356\n",
      "Epochs 172 loss 0.1347\n",
      "Epochs 173 loss 0.1338\n",
      "Epochs 174 loss 0.1329\n",
      "Epochs 175 loss 0.1320\n",
      "Epochs 176 loss 0.1311\n",
      "Epochs 177 loss 0.1303\n",
      "Epochs 178 loss 0.1294\n",
      "Epochs 179 loss 0.1285\n",
      "Epochs 180 loss 0.1276\n",
      "Epochs 181 loss 0.1268\n",
      "Epochs 182 loss 0.1259\n",
      "Epochs 183 loss 0.1250\n",
      "Epochs 184 loss 0.1242\n",
      "Epochs 185 loss 0.1234\n",
      "Epochs 186 loss 0.1225\n",
      "Epochs 187 loss 0.1217\n",
      "Epochs 188 loss 0.1208\n",
      "Epochs 189 loss 0.1200\n",
      "Epochs 190 loss 0.1192\n",
      "Epochs 191 loss 0.1184\n",
      "Epochs 192 loss 0.1176\n",
      "Epochs 193 loss 0.1168\n",
      "Epochs 194 loss 0.1160\n",
      "Epochs 195 loss 0.1152\n",
      "Epochs 196 loss 0.1144\n",
      "Epochs 197 loss 0.1137\n",
      "Epochs 198 loss 0.1129\n",
      "Epochs 199 loss 0.1121\n",
      "Epochs 200 loss 0.1114\n",
      "Epochs 201 loss 0.1107\n",
      "Epochs 202 loss 0.1099\n",
      "Epochs 203 loss 0.1092\n",
      "Epochs 204 loss 0.1085\n",
      "Epochs 205 loss 0.1078\n",
      "Epochs 206 loss 0.1071\n",
      "Epochs 207 loss 0.1065\n",
      "Epochs 208 loss 0.1058\n",
      "Epochs 209 loss 0.1051\n",
      "Epochs 210 loss 0.1045\n",
      "Epochs 211 loss 0.1039\n",
      "Epochs 212 loss 0.1032\n",
      "Epochs 213 loss 0.1026\n",
      "Epochs 214 loss 0.1020\n",
      "Epochs 215 loss 0.1014\n",
      "Epochs 216 loss 0.1008\n",
      "Epochs 217 loss 0.1002\n",
      "Epochs 218 loss 0.0996\n",
      "Epochs 219 loss 0.0990\n",
      "Epochs 220 loss 0.0985\n",
      "Epochs 221 loss 0.0979\n",
      "Epochs 222 loss 0.0973\n",
      "Epochs 223 loss 0.0968\n",
      "Epochs 224 loss 0.0963\n",
      "Epochs 225 loss 0.0957\n",
      "Epochs 226 loss 0.0952\n",
      "Epochs 227 loss 0.0947\n",
      "Epochs 228 loss 0.0942\n",
      "Epochs 229 loss 0.0936\n",
      "Epochs 230 loss 0.0931\n",
      "Epochs 231 loss 0.0926\n",
      "Epochs 232 loss 0.0921\n",
      "Epochs 233 loss 0.0917\n",
      "Epochs 234 loss 0.0912\n",
      "Epochs 235 loss 0.0907\n",
      "Epochs 236 loss 0.0902\n",
      "Epochs 237 loss 0.0898\n",
      "Epochs 238 loss 0.0893\n",
      "Epochs 239 loss 0.0888\n",
      "Epochs 240 loss 0.0884\n",
      "Epochs 241 loss 0.0879\n",
      "Epochs 242 loss 0.0875\n",
      "Epochs 243 loss 0.0871\n",
      "Epochs 244 loss 0.0866\n",
      "Epochs 245 loss 0.0862\n",
      "Epochs 246 loss 0.0858\n",
      "Epochs 247 loss 0.0853\n",
      "Epochs 248 loss 0.0849\n",
      "Epochs 249 loss 0.0845\n",
      "Epochs 250 loss 0.0841\n",
      "Epochs 251 loss 0.0837\n",
      "Epochs 252 loss 0.0833\n",
      "Epochs 253 loss 0.0829\n",
      "Epochs 254 loss 0.0825\n",
      "Epochs 255 loss 0.0821\n",
      "Epochs 256 loss 0.0817\n",
      "Epochs 257 loss 0.0813\n",
      "Epochs 258 loss 0.0809\n",
      "Epochs 259 loss 0.0805\n",
      "Epochs 260 loss 0.0802\n",
      "Epochs 261 loss 0.0798\n",
      "Epochs 262 loss 0.0794\n",
      "Epochs 263 loss 0.0791\n",
      "Epochs 264 loss 0.0787\n",
      "Epochs 265 loss 0.0783\n",
      "Epochs 266 loss 0.0780\n",
      "Epochs 267 loss 0.0776\n",
      "Epochs 268 loss 0.0773\n",
      "Epochs 269 loss 0.0769\n",
      "Epochs 270 loss 0.0766\n",
      "Epochs 271 loss 0.0762\n",
      "Epochs 272 loss 0.0759\n",
      "Epochs 273 loss 0.0755\n",
      "Epochs 274 loss 0.0752\n",
      "Epochs 275 loss 0.0749\n",
      "Epochs 276 loss 0.0745\n",
      "Epochs 277 loss 0.0742\n",
      "Epochs 278 loss 0.0739\n",
      "Epochs 279 loss 0.0735\n",
      "Epochs 280 loss 0.0732\n",
      "Epochs 281 loss 0.0729\n",
      "Epochs 282 loss 0.0726\n",
      "Epochs 283 loss 0.0723\n",
      "Epochs 284 loss 0.0719\n",
      "Epochs 285 loss 0.0716\n",
      "Epochs 286 loss 0.0713\n",
      "Epochs 287 loss 0.0710\n",
      "Epochs 288 loss 0.0707\n",
      "Epochs 289 loss 0.0704\n",
      "Epochs 290 loss 0.0701\n",
      "Epochs 291 loss 0.0698\n",
      "Epochs 292 loss 0.0695\n",
      "Epochs 293 loss 0.0692\n",
      "Epochs 294 loss 0.0689\n",
      "Epochs 295 loss 0.0686\n",
      "Epochs 296 loss 0.0683\n",
      "Epochs 297 loss 0.0680\n",
      "Epochs 298 loss 0.0677\n",
      "Epochs 299 loss 0.0674\n",
      "Epochs 300 loss 0.0671\n",
      "Epochs 301 loss 0.0669\n",
      "Epochs 302 loss 0.0666\n",
      "Epochs 303 loss 0.0663\n",
      "Epochs 304 loss 0.0660\n",
      "Epochs 305 loss 0.0657\n",
      "Epochs 306 loss 0.0654\n",
      "Epochs 307 loss 0.0652\n",
      "Epochs 308 loss 0.0649\n",
      "Epochs 309 loss 0.0646\n",
      "Epochs 310 loss 0.0643\n",
      "Epochs 311 loss 0.0640\n",
      "Epochs 312 loss 0.0638\n",
      "Epochs 313 loss 0.0635\n",
      "Epochs 314 loss 0.0632\n",
      "Epochs 315 loss 0.0630\n",
      "Epochs 316 loss 0.0627\n",
      "Epochs 317 loss 0.0624\n",
      "Epochs 318 loss 0.0622\n",
      "Epochs 319 loss 0.0619\n",
      "Epochs 320 loss 0.0616\n",
      "Epochs 321 loss 0.0614\n",
      "Epochs 322 loss 0.0611\n",
      "Epochs 323 loss 0.0609\n",
      "Epochs 324 loss 0.0606\n",
      "Epochs 325 loss 0.0604\n",
      "Epochs 326 loss 0.0601\n",
      "Epochs 327 loss 0.0599\n",
      "Epochs 328 loss 0.0596\n",
      "Epochs 329 loss 0.0594\n",
      "Epochs 330 loss 0.0591\n",
      "Epochs 331 loss 0.0589\n",
      "Epochs 332 loss 0.0586\n",
      "Epochs 333 loss 0.0584\n",
      "Epochs 334 loss 0.0582\n",
      "Epochs 335 loss 0.0579\n",
      "Epochs 336 loss 0.0577\n",
      "Epochs 337 loss 0.0575\n",
      "Epochs 338 loss 0.0573\n",
      "Epochs 339 loss 0.0570\n",
      "Epochs 340 loss 0.0568\n",
      "Epochs 341 loss 0.0566\n",
      "Epochs 342 loss 0.0564\n",
      "Epochs 343 loss 0.0562\n",
      "Epochs 344 loss 0.0560\n",
      "Epochs 345 loss 0.0557\n",
      "Epochs 346 loss 0.0555\n",
      "Epochs 347 loss 0.0553\n",
      "Epochs 348 loss 0.0551\n",
      "Epochs 349 loss 0.0549\n",
      "Epochs 350 loss 0.0547\n",
      "Epochs 351 loss 0.0545\n",
      "Epochs 352 loss 0.0543\n",
      "Epochs 353 loss 0.0541\n",
      "Epochs 354 loss 0.0539\n",
      "Epochs 355 loss 0.0538\n",
      "Epochs 356 loss 0.0536\n",
      "Epochs 357 loss 0.0534\n",
      "Epochs 358 loss 0.0532\n",
      "Epochs 359 loss 0.0530\n",
      "Epochs 360 loss 0.0528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 361 loss 0.0526\n",
      "Epochs 362 loss 0.0525\n",
      "Epochs 363 loss 0.0523\n",
      "Epochs 364 loss 0.0521\n",
      "Epochs 365 loss 0.0519\n",
      "Epochs 366 loss 0.0517\n",
      "Epochs 367 loss 0.0516\n",
      "Epochs 368 loss 0.0514\n",
      "Epochs 369 loss 0.0512\n",
      "Epochs 370 loss 0.0511\n",
      "Epochs 371 loss 0.0509\n",
      "Epochs 372 loss 0.0507\n",
      "Epochs 373 loss 0.0506\n",
      "Epochs 374 loss 0.0504\n",
      "Epochs 375 loss 0.0502\n",
      "Epochs 376 loss 0.0501\n",
      "Epochs 377 loss 0.0499\n",
      "Epochs 378 loss 0.0497\n",
      "Epochs 379 loss 0.0496\n",
      "Epochs 380 loss 0.0494\n",
      "Epochs 381 loss 0.0493\n",
      "Epochs 382 loss 0.0491\n",
      "Epochs 383 loss 0.0489\n",
      "Epochs 384 loss 0.0488\n",
      "Epochs 385 loss 0.0486\n",
      "Epochs 386 loss 0.0485\n",
      "Epochs 387 loss 0.0483\n",
      "Epochs 388 loss 0.0482\n",
      "Epochs 389 loss 0.0480\n",
      "Epochs 390 loss 0.0479\n",
      "Epochs 391 loss 0.0477\n",
      "Epochs 392 loss 0.0476\n",
      "Epochs 393 loss 0.0474\n",
      "Epochs 394 loss 0.0473\n",
      "Epochs 395 loss 0.0471\n",
      "Epochs 396 loss 0.0470\n",
      "Epochs 397 loss 0.0468\n",
      "Epochs 398 loss 0.0467\n",
      "Epochs 399 loss 0.0466\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24808ebbeb8>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.prediction(X_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705882352941176"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(outputs==Y_values)/Y_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Dataset/pokemon/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2236.jpg\n"
     ]
    }
   ],
   "source": [
    "test = df_test.values\n",
    "print(test[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = test.shape[0]\n",
    "X_test = []\n",
    "title_out = []\n",
    "for i in range(n):\n",
    "    title = test[i][0]\n",
    "    img = cv2.imread(\"Dataset/pokemon/Images/\"+title)\n",
    "    try:\n",
    "        if img == None:\n",
    "            continue\n",
    "\n",
    "    except:\n",
    "        img = cv2.resize(img,(100,100))\n",
    "        img = img.flatten()\n",
    "        title_out.append(title)\n",
    "        X_test.append(img)\n",
    "title_out = np.array(title_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemonblb={\n",
    "    '0':\"Pikachu\",\n",
    "    '1':\"Bulbasaur\",\n",
    "    '2':\"Charmander\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = outputs.shape[0]\n",
    "new_output = []\n",
    "for ix in range(m):\n",
    "    new_output.append(pokemonblb[str(outputs[ix])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bulbasaur', 'Pikachu', 'Bulbasaur', 'Charmander', 'Pikachu', 'Charmander', 'Pikachu', 'Bulbasaur', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Bulbasaur', 'Bulbasaur', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Charmander', 'Charmander', 'Pikachu', 'Charmander', 'Charmander', 'Bulbasaur', 'Pikachu', 'Charmander', 'Charmander', 'Charmander', 'Pikachu', 'Bulbasaur', 'Charmander', 'Charmander', 'Pikachu', 'Pikachu', 'Charmander', 'Bulbasaur', 'Pikachu', 'Bulbasaur', 'Charmander', 'Pikachu', 'Charmander', 'Bulbasaur', 'Charmander', 'Charmander', 'Pikachu', 'Charmander', 'Charmander', 'Bulbasaur', 'Bulbasaur', 'Charmander', 'Charmander', 'Bulbasaur', 'Pikachu', 'Charmander', 'Charmander', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Pikachu', 'Charmander', 'Pikachu', 'Bulbasaur', 'Bulbasaur', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Pikachu', 'Pikachu', 'Bulbasaur', 'Bulbasaur', 'Pikachu', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Bulbasaur', 'Pikachu', 'Charmander', 'Charmander', 'Charmander', 'Bulbasaur', 'Bulbasaur', 'Bulbasaur', 'Pikachu', 'Bulbasaur', 'Pikachu', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Pikachu', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Charmander', 'Charmander', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Pikachu', 'Pikachu', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Charmander', 'Charmander', 'Charmander', 'Charmander', 'Pikachu', 'Charmander', 'Bulbasaur', 'Pikachu', 'Bulbasaur', 'Pikachu', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Charmander', 'Charmander', 'Bulbasaur', 'Bulbasaur', 'Charmander', 'Bulbasaur', 'Pikachu']\n"
     ]
    }
   ],
   "source": [
    "print(new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  pd.DataFrame(data=new_output,columns=[\"NameOfPokemon\"]) \n",
    "y.to_csv(\"pokemonOutput3.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from Visualize import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123,) (136,)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape,Y_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [123, 136]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-43eebc27289b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [123, 136]"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(outputs,Y_values)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
